{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewsAnalysis_UsingPytorch_internship.ipynb",
      "provenance": [],
      "mount_file_id": "1FJyFFNJCw1g0ACcjfZxKyiKAdAhLWAGM",
      "authorship_tag": "ABX9TyNiWhjjXQilAhVgpuVWAmrF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saksham1211/Marketingai_Internship/blob/master/NewsAnalysis_UsingPytorch_internship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMXyg9_bPBWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nm0TKGyWEA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('news.csv', encoding = 'unicode_escape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVP2Rn3rWNji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb2bc8cd-43e2-4a84-f725-51c4ed9f506e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Date</th>\n",
              "      <th>Heading</th>\n",
              "      <th>NewsType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
              "      <td>1/1/2015</td>\n",
              "      <td>sindh govt decides to cut public transport far...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
              "      <td>1/2/2015</td>\n",
              "      <td>asia stocks up in new year trad</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
              "      <td>1/5/2015</td>\n",
              "      <td>hong kong stocks open 0.66 percent lower</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
              "      <td>1/6/2015</td>\n",
              "      <td>asian stocks sink euro near nine year</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
              "      <td>1/6/2015</td>\n",
              "      <td>us oil prices slip below 50 a barr</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Article  ...  NewsType\n",
              "0  KARACHI: The Sindh government has decided to b...  ...  business\n",
              "1  HONG KONG: Asian markets started 2015 on an up...  ...  business\n",
              "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  ...  business\n",
              "3  HONG KONG: Asian markets tumbled Tuesday follo...  ...  business\n",
              "4  NEW YORK: US oil prices Monday slipped below $...  ...  business\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQTkc-u1bxRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data.NewsType\n",
        "x= data.drop('NewsType', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kESJW5-Db6SO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "868ed503-3775-49c1-f4f3-207d043cf8ee"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "x_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Date</th>\n",
              "      <th>Heading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2310</th>\n",
              "      <td>MANCHESTER:  Moeen Ali took two wickets as Eng...</td>\n",
              "      <td>7/25/2016</td>\n",
              "      <td>Pakistan 161 5 at tea as England move closer t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>Hertogenbosch, Netherlands: Nicolas Mahut warm...</td>\n",
              "      <td>6/13/2016</td>\n",
              "      <td>Mahut claims third s Hertogenbosch ti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>strong&gt;ISLAMABAD: Pakistan International Airli...</td>\n",
              "      <td>7/29/2016</td>\n",
              "      <td>PIA signs contact lease three A 330s Sri L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1311</th>\n",
              "      <td>strong&gt;ZURICH: Gianni Infantino vowed on Frida...</td>\n",
              "      <td>2/27/2016</td>\n",
              "      <td>Infantino chosen to lead FIFA into new er</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>strong&gt;LONDON: England paceman Stuart Broad be...</td>\n",
              "      <td>5/26/2016</td>\n",
              "      <td>Blooming partnership Anderson pleases Stuart B...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Article  ...                                            Heading\n",
              "2310  MANCHESTER:  Moeen Ali took two wickets as Eng...  ...  Pakistan 161 5 at tea as England move closer t...\n",
              "1959  Hertogenbosch, Netherlands: Nicolas Mahut warm...  ...              Mahut claims third s Hertogenbosch ti\n",
              "823   strong>ISLAMABAD: Pakistan International Airli...  ...         PIA signs contact lease three A 330s Sri L\n",
              "1311  strong>ZURICH: Gianni Infantino vowed on Frida...  ...          Infantino chosen to lead FIFA into new er\n",
              "1805  strong>LONDON: England paceman Stuart Broad be...  ...  Blooming partnership Anderson pleases Stuart B...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHNNdc9IEdR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01d42579-fe03-44b5-c1c3-b30e942d212c"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2153, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBWlxJTMElqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "adbfcc70-4f20-4f58-d937-1bc88a42a81e"
      },
      "source": [
        "!pip install torch<=1.2.0\n",
        "!pip install torchtext\n",
        "%matplotlib inline"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: =1.2.0: No such file or directory\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i77ZMluGG-sK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "3d5d4fb9-7c21-465c-dd0a-54243c7ce97e"
      },
      "source": [
        "pip install https://github.com/pytorch/text/archive/master.zip"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/pytorch/text/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/pytorch/text/archive/master.zip\n",
            "\u001b[K     | 3.9MB 7.2MB/s\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.12.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.6.0-cp36-none-any.whl size=68047 sha256=2fcf74d869b2e50b20d54feeef29f779cdb0e6a581e23920326f8dc5241196f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-avmszk27/wheels/5a/86/3d/30ae7dfdfeb1748bb11b3da173fb9634141fbb39e9e9847317\n",
            "Successfully built torchtext\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.85 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cpqaMcbHMYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ff1a0d7b-b8b8-4a82-acad-b157fee10d03"
      },
      "source": [
        "import torch\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "NGRAMS = 2\n",
        "import os\n",
        "if not os.path.isdir('./.data'):\n",
        "\tos.mkdir('./.data')\n",
        "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
        "    root='./.data', ngrams=NGRAMS, vocab=None)\n",
        "BATCH_SIZE = 16\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ag_news_csv.tar.gz: 11.8MB [00:00, 128MB/s]\n",
            "120000lines [00:09, 12809.01lines/s]\n",
            "120000lines [00:19, 6262.48lines/s]\n",
            "7600lines [00:01, 6374.38lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyuTkXqRHTi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class TextSentiment(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jaz8Q8f9HvLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
        "EMBED_DIM = 32\n",
        "NUN_CLASS = len(train_dataset.get_labels())\n",
        "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQZgmeKYH_1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    label = torch.tensor([entry[0] for entry in batch])\n",
        "    text = [entry[1] for entry in batch]\n",
        "    offsets = [0] + [len(entry) for entry in text]\n",
        "  \n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text = torch.cat(text)\n",
        "    return text, offsets, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0e3RwbrILUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "    \n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TewQ3L_KIyCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "bf01a5d1-8e8f-48dc-c15b-63b8f1ecfb25"
      },
      "source": [
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 5\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "train_len = int(len(train_dataset) * 0.95)\n",
        "sub_train_, sub_valid_ = \\\n",
        "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 29 seconds\n",
            "\tLoss: 0.0261(train)\t|\tAcc: 84.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 90.9%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 30 seconds\n",
            "\tLoss: 0.0119(train)\t|\tAcc: 93.7%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 90.7%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 30 seconds\n",
            "\tLoss: 0.0069(train)\t|\tAcc: 96.4%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 91.4%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 31 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 98.1%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 91.4%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 34 seconds\n",
            "\tLoss: 0.0022(train)\t|\tAcc: 99.0%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 90.3%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "johYuIQ-JAQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "035db053-37c9-464f-c40f-b238be972813"
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_dataset)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.0002(test)\t|\tAcc: 89.8%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecF8_KiDKEvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9630cb97-1d2b-476d-f932-7dcc3b9bf8f8"
      },
      "source": [
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "ag_news_label = {1 : \"World\",\n",
        "                 2 : \"Sports\",\n",
        "                 3 : \"Business\",\n",
        "                 4 : \"Sci/Tec\"}\n",
        "\n",
        "def predict(text, model, vocab, ngrams):\n",
        "    tokenizer = get_tokenizer(\"basic_english\")\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor([vocab[token]\n",
        "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = str(data['Article'][0])\n",
        "\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a Business news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCc-pS1rKbFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}